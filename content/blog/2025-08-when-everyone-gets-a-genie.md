---
authors: ['bj√∂rn']
date: '2025-08-10T18:40:00+08:00'
lastmod: '2025-08-10T18:40:00+08:00'
title: When everyone gets a genie
subtitle: learning to handle expertise you didn't earn
tags:
  - thinking-out-loud
  - ai
  - genie
  - learning
series: ['learning-with-genies']
daily: ['2025-08-10']
---

We've always had to figure out who to trust for expertise, but until now, that access wasn't universal. Used to be the bloke at the pub who 'knew things,' or that friend of a friend who could fix computers (me as a kid), or books if you had the patience. Rich people had their 'real' experts on call, though Bernie Madoff shows how well that could work out.

The internet changed things, sure. Suddenly you could reach out to actual experts, find communities, and learn from people across the world. But you still needed judgment, because you could also find a community that agreed the earth was flat, so, you know, mixed bag.

What hasn't changed is we've always had to figure out who to trust. What's changing is how we get our answers, and who gets to sound like an expert.

<!--more-->

## My dinner with Mark

I went for dinner with Mr. Bossman, or Mark as he's also known, and we ended up talking about AI because we're looking to make genies available to all programmers at work, and we want to do it safely. While talking about what we're doing, he says he doesn't think we'll have programmers like we do today, that programming is probably going to end up being more like normal language that compiles down into software (all about that prompt).

I'm not sure that's the full story, thinking about how we've progressed with, for example, assembly programming. Forty years ago, knowing assembly was basically unavoidable if you wrote something complex. Now? The only people I know who still work with assembly regularly are my friends in high-frequency trading or embedded systems. Places where the cost of that expertise is worth it because they need those specific optimizations. It doesn't mean it **went away**, but yeah, we use high-level languages (more akin to spoken languages than assembly) to write software now.

Us seniors have always thought that the 'kids today' don't know the basics, where the basics are defined as whatever level of abstraction we learned when we got started. Assembly folks complained about C programmers. C programmers complained about scripting languages. Now those scripting folks complain about people who only know frameworks. A lot of people I come across don't really know how to set up a Linux box, and that was required for me because otherwise I couldn't host anything. But why should they know it now?

Mark connected with this and said that the people senior to him all knew assembly to some degree, but starting at C, he never did. He didn't bother with yacc, lex, any of that, because the compiler handled it. What was core skills for them became optional for him. Every generation's "_minimum viable knowledge_" shifts up a layer of abstraction.

I think we're coming to a point where more people are able to get the output of programming: something that does what they need, even if it's held together with digital duct tape. Which is [Jevons' paradox](https://en.wikipedia.org/wiki/Jevons_paradox) at work: when something becomes more efficient, we don't use less of it, we use _way more_. And all those people using it poorly? That's not a bug, that's the feature.

## The commoditization pattern

Every technology does this. Think about typing. Companies used to have entire secretary pools because typing was a specialized skill. Now? Everyone types. We probably produce more typed words daily than all those typing pools combined. The skill didn't disappear, it just became so commoditized that we don't even think of it as a skill anymore. But writing, _oh boy_, that's a skill and we recognize good vs. bad even if everyone can type.

Socrates complained that writing was [a terrible way to share knowledge](https://fs.blog/an-old-argument-against-writing/), that it would make people "seem to know much while for the most part they know nothing." (Sound familiar?) When calculators came out, people panicked that kids wouldn't understand math anymore and society would collapse!!

Some examples of how we've ruined the fabric of society:

| The panic                         | The reality                                       |
|-----------------------------------|---------------------------------------------------|
| "Kids won't memorize anything!"   | They don't. They Google it. Works fine.           |
| "No one will know mental math!"   | They don't. Phone calculator. Works fine.         |
| "People can't follow directions!" | They can't. GPS does it step-by-step. Works fine. |
| "No one will really program!"     | Probably the same?                                |

I know how useful 'barely good enough' programming can be, because back at my first job, I built a stock-take system over a weekend with a friend. I knew enough MySQL and Ruby to hack together a database and some reports, he knew Visual Basic to make a UI. We had laptops on shopping carts with USB barcode scanners. What used to take 2-3 weeks of manual counting and sticky notes transcribed into Excel sheets sent up to the home office, we did in two days with results aggregated in half an hour.

Was it elegant code? God no. Did it solve a real problem? Absolutely. I spent about five years at this company, as the first and only 'IT employee,' building little tools and scripts to help make our days simpler. Funny thing is, I was hired to fix printers and keep the POS running, but once I'd gotten that under control, people started giving me purchasing assistant work, and, well, I knew just enough programming to make that go away too. At one point our ERP vendor said they'd never seen a customer with as much automation as us, which was really just me getting sick of manual work and knowing _just enough_ programming to make it go away.

And that's commoditization at work. The specialized skill becomes rare and expensive, while the everyday version becomes accessible but, let's be honest, pretty shitty. And you know what? There's nothing wrong with shitty if it solves real problems. The expertise, all those 'it depends' answers we love to give, that comes in when you need to scale it, secure it, make it last. But first? First you just need it to work.

## What's different

We're not just replacing horses with engines. We're replacing the process of acquiring expertise with cock-sure genies that answer everything instantly.

It's like how, in parts of history, being fat signalled wealth, today, abundance is everywhere and the signal has flipped. Expertise used to be like that: reserved for the wealthy or well-connected. Now everyone gets _apparent expertise_. And just like abundant food doesn't make you healthy (without self-control), abundant answers don't make the decision correct. 

Plus, when the wealthy got bad advice, they had lawyers and fall guys. When we get bad advice from a genie? Well, good luck explaining that in the post-mortem when [your name was on it.]({{< relref "2025-07-your-name-is-still-on-it.md" >}})

## Spreading out, not disappearing

Those assembly programmers didn't disappear, they just don't all work at IBM anymore. They're scattered across trading firms, embedded systems shops, game companies, and more. The expertise spreads out because it _can_, you don't need to be at one of three companies to use your deep skills anymore.

(And yeah, I know someone's thinking "but what about all the jobs that will disappear?" We don't have many [manure shovelers](https://en.wikipedia.org/wiki/Great_horse_manure_crisis_of_1894) anymore since cars replaced horses. We also have social media managers, cloud architects, and whatever it'll mean to be a "context engineer." The jobs change. They always have.)

Same thing will happen with what we call programming today. The absolute number might not even go down much. Maybe we'll have fewer at big tech companies and more scattered across regular companies, building internal tools, being the person who knows how to make the genies behave.

Kind of like how most companies have someone who's 'good with computers' to fix Outlook or figure out why the printer isn't working. They don't need to be highly educated in IT, they just need to know how to figure things out and stick with it.

## Which skills do you keep?

This is like my relationship with cars. I can drive, change oil, swap tires. Am I the best at parallel parking? Nope, and I'll drive a bit further to avoid a tight spot. Should you trust me to race? Definitely not. But I can safely get on the highway and go reasonably fast when it's appropriate (those spots we've built up to [let Gripen land and take off](https://www.joint-forces.com/exercise-news/73407-swedish-gripen-fighters-landing-on-highways)).

Some skills I want, some I don't care about. And that's fine, **until** the world expects me to be good at the ones I've skipped.

Testing is one of those skills that shows this tension perfectly. I'm a {{< define "TDD" "Test Driven Development" >}} person, it's a fantastic design tool, not just bug-catching. But many programmers still treat it as an afterthought because "how can you know what to implement before you build it?" That resistance is exactly why it's valuable: it forces you to think differently and know what _outcome_ you want. And that's why genies make things dangerous: they can write tests that look good, but if you don't understand testing as design, you won't know when you're building the wrong thing with great test coverage.

## Deciding what sticks

So how do we learn when we have genies answering everything? I've been experimenting with this. My cooking has genuinely improved with an AI coach, but I'm not just following recipes. I ask _why_ we're using these ingredients, _why_ this technique works, what the char is actually doing to the flavor. Cooking is something I want to get better at, no intention to become a proper chef, but being able to whip up dinner, using up my ingredients, and liking the taste? That'd be nice.

I've been using [Grammarly](https://www.grammarly.com) for years, and I know my writing has improved from it. Not because it fixes things for me, but because I've started catching the mistakes before the red underline shows up. Though we still disagree about commas, Swedish habits die hard.

There's this thing called [tacit knowledge](https://commoncog.com/the-tacit-knowledge-series/), stuff we know but can't explain, that gut feel that something about this code is wrong but you can't exactly pinpoint it. You write the same code again and again, get the same PR feedback again and again, until it clicks. But does it have to be that painful? I wonder if the genie can actually help us create better ways to build tacit knowledge, since it can generate examples and evaluate them. Like, I could ask it to show me ten variations of the same function, each with different edge cases, and develop that pattern recognition faster.

Maybe a good way for me to be more intentional is to write down which skills I want to learn. The ones where I want to gain that tacit knowledge, and also take it further so I can explain it, and not just feel it. Cooking and writing are both on that list. So is design and architecture when programming, and I'm much further along there. (Thanks Daryl [for the inspiration.](https://daryl.wakatara.com/counting-coup/))

## What I'm exploring next

I'm not a breathless AI fan. But, for me, it has turned into an intellectual sparring partner, someone to bounce ideas off who helps me figure out what I _truly want._ The genie shows me options, my gut tells me which ones I like or not, and I try to listen to that gut feeling and understand _why_.

Because [apparently our brains are turning to mush](https://time.com/7295195/ai-chatgpt-google-learning-school/) because of AI. I don't buy it, but I also don't intend to let it happen to me. I still want to know which skills matter to me, which ones I'm keeping sharp, and which ones I'm okay with the genie handling as long as I can check the output.

I don't have this figured out. But I'm pretty sure the answer isn't to pretend the genies aren't here, I have enough evidence that I get help from them, and it's definitely not to blindly let them do everything without thinking. So I'm gonna keep poking at this, probably change my mind a few times, and see what sticks.

This is the first post in a series where I'll be figuring this out in public. How to decide what to learn deeply, how to tell when you're just parroting the genie, and how to keep judgment sharp when answers are cheap. Because your name is still on whatever you send out, genie or no genie.

We're all in our AI twenties right now, trying to figure out how to ride these [motorcycles]({{< relref "2025-07-your-name-is-still-on-it.md" >}}) without crashing. Might as well compare notes along the way.
